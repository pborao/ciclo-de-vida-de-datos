{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los paquetes que necesitamos\n",
    "import pandas as pd\n",
    "#librería para http\n",
    "import requests\n",
    "# Para trabajar con archivos csv\n",
    "import csv\n",
    "# Librería para hacer web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Inicializamos lista con los meses \n",
    "lista = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\"]\n",
    "#Inicializamos con las columnas correspondientes a los datos que vamos a obtener\n",
    "columnas = ['ID','Tipo','Coordenadas','Fecha','Hora','Magnitud','Distancia','Ubicacion','Pais']\n",
    "#Creando el dataframe\n",
    "df_new = pd.DataFrame(columns = columnas)\n",
    "df = pd.DataFrame(columns = columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada uno de los meses\n",
    "for x in range(0,len(lista)):\n",
    "#Creamos la URL del mes y obtenemos el código HTML de esa mes \n",
    "    URL = 'https://www.volcanodiscovery.com/earthquakes/archive/2020-'+lista[x]+'.html'      \n",
    "    page = requests.get(URL)\n",
    "#Convertimos a objeto de la clase BeautifulSoup con el parseador a utilizar\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "# Creamos una lista con los posibles valores que hemos identificado como diferentes tipos de seismo\n",
    "    qi = [\"q3\",\"q4\",\"q5\",\"q6\",\"q7\",\"q8\"]\n",
    "# Iniciamos un bucle para cada uno de los qi\n",
    "    for i in range(0,len(qi)):\n",
    "# Obtenemos todos los elementos tr para la clase qi (de la iteración del bucle)\n",
    "        q = soup.find_all('tr', class_=qi[i])\n",
    "        nroFila=1\n",
    "# Para cada fila encontrada, construimos los datos\n",
    "        for job_elem in q: \n",
    "#Trabajamos el string para quedarnos con lo que nos interesa\n",
    "            reportes_sismo = job_elem.find('a', class_='sl2')\n",
    "            reportes_sismo = str(reportes_sismo).replace('<a class=\"sl2\" href=\"','')\n",
    "            reporte_id = reportes_sismo[23:30] \n",
    "            coordenadas_sismo = job_elem.find_all('a', href = True, title = True, onclick = True, style = False) \n",
    "            coordenadas_sismo = str(coordenadas_sismo).replace(' - Show on map\">Map</a>]','')\n",
    "            coordenadas_sismo = coordenadas_sismo.split('title=\"')[1]\n",
    "            coordenadas_sismo = str(coordenadas_sismo).replace(' / ',',')\n",
    "            names = []\n",
    "            filas = []\n",
    "#Recogemos toda la información y la formateamos con funciones de texto eliminando lo que no interesa como dato \n",
    "# Bucle para repasar todas las 'celdas' que contienen la información que queremos extraer.\n",
    "            for celda in job_elem.find_all('td'):\n",
    "                name=celda.text\n",
    "                names.append(name)\n",
    "            fechas_horas = names[0].split('UTC')\n",
    "            fecha_hora = fechas_horas[0].split(' ')\n",
    "#Dividmos en dos campos la fecha y la hora            \n",
    "            fecha = fecha_hora[0]\n",
    "            hora = fecha_hora[1]\n",
    "#Formateamos la información de magnitud eliminando y troceando para quedarnos con los datos que interesan\n",
    "            mags_dists = str(names[1]).replace(' - Info','')\n",
    "            mags_dists = mags_dists.split(' / ')\n",
    "            magnitud = str(mags_dists[0]).replace('M ','')\n",
    "            if len(mags_dists) > 1:\n",
    "                distancia = str(mags_dists[1]).replace(' km','')\n",
    "            ubicaciones = str(names[3]).replace('I FELT IT ','')\n",
    "            ubicaciones = ubicaciones.split(', ')\n",
    "            ubicacion = ubicaciones[0]\n",
    "            tipo = qi[i]\n",
    "            if len(ubicaciones) > 1:\n",
    "                paises = ubicaciones[1]\n",
    "                paises = str(paises).replace(' report','')\n",
    "                paises = str(paises).replace('s','')\n",
    "            elif len(ubicaciones) > 2:\n",
    "                region = ubicaciones[2]\n",
    "            else:\n",
    "                paises = ' '\n",
    "#Incrementamos para pasar al siguiente tipo de 'q'        \n",
    "            nroFila=nroFila+1\n",
    "# Utilizamos el método append para añadir la información que hemos obtenido\n",
    "            df=df.append({'ID': reporte_id,'Tipo': tipo, 'Coordenadas': coordenadas_sismo,'Fecha': fecha,'Hora': hora,'Magnitud': magnitud,\n",
    "                              'Distancia': distancia,'Ubicacion': ubicacion,'Pais': paises} , ignore_index=True)\n",
    "        df_new = pd.concat([df_new, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez ya hemos iterado por todos los elementos de la lista (de todos los meses) escribimos en el fichero csv\n",
    "df_new.to_csv('earthquakes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
